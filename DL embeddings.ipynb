{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#random seeds for stochastic parts of neural network \n",
    "np.random.seed(10)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(15)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Merge, Reshape, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import SGD\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/aichallenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (6,16,17,26,40,41,49,53,97,98,99,100,104,107,109,112,127,128,129,130,220,221,222) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (6,16,17,26,40,41,49,53,54,55,100,104,107,109,112,127,128,129,130,153,171,220,221,222,225,226,227) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194.551185131073\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1=time.time()\n",
    "train = pd.read_table('challengeData.tsv')\n",
    "test = pd.read_table('scoring_set.tsv')\n",
    "train_imputed = pd.read_csv('train_imputed.csv')\n",
    "test_imputed = pd.read_csv('test_imputed.csv')\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 237)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imputed.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1888195, 42)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226140, 42)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed = train_imputed.drop('Unnamed: 0',axis=1)\n",
    "test_imputed = test_imputed.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011782646179199219\n"
     ]
    }
   ],
   "source": [
    "#remove data set name from columns names to make it uniform\n",
    "t1=time.time()\n",
    "columns=[]\n",
    "for col in train.columns:\n",
    "    columns.append(col.replace('challenge_data.',''))\n",
    "train.columns=columns\n",
    "columns=[]\n",
    "for col in test.columns:\n",
    "    columns.append(col.replace('scoring_set.',''))\n",
    "test.columns=columns\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23860"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['renewed_yorn'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812535285949707\n"
     ]
    }
   ],
   "source": [
    "#remove the rows where 'challenge_data.renewed_yorn' is null in training data\n",
    "t1=time.time()\n",
    "train=train[train['renewed_yorn'].notnull()]\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.4706315994262695\n"
     ]
    }
   ],
   "source": [
    "#remove the 'challenge_data.renewed_yorn' from training and test data and move it to a seperate variable\n",
    "t1=time.time()\n",
    "train_y=train['renewed_yorn']\n",
    "train = train.drop(['renewed_yorn','zip_code'],axis=1)\n",
    "test_y=test['renewed_yorn']\n",
    "test = test.drop(['renewed_yorn','zip_code'],axis=1)\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.60910058021545\n"
     ]
    }
   ],
   "source": [
    "#remove columns which have many null values\n",
    "t1=time.time()\n",
    "percent = (test.isnull().sum()/test.isnull().count())\n",
    "test.columns[percent>0.5]\n",
    "#We would ignore all these 102 columns so we are left with 135 columns\n",
    "len(test.columns[percent>0.5])\n",
    "#all_clean_columns=train.columns[percent==0]\n",
    "#train_clean=train[all_clean_columns]\n",
    "unclean_columns=test.columns[percent>0.5]\n",
    "clean_columns=test.columns[percent==0]\n",
    "train = train.drop(unclean_columns,axis=1)\n",
    "test = test.drop(unclean_columns,axis=1)\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unclean_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()\n",
    "percent = (test.isnull().sum()/test.isnull().count())\n",
    "target_columns=test.columns[percent>0]\n",
    "train_missing=train[target_columns]\n",
    "test_missing=test[target_columns]\n",
    "train = train.drop(target_columns,axis=1)\n",
    "test = test.drop(target_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.252274990081787\n"
     ]
    }
   ],
   "source": [
    "#Remove columns which have too many categories and is string type\n",
    "t1=time.time()\n",
    "messy_columns = []\n",
    "for col in target_columns:\n",
    "    if(train_missing[col].dtype=='O' and len(train_missing[col].unique())>=10):\n",
    "        messy_columns.append(col)\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 56 messy columns are removed\n",
    "len(messy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_missing.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4593737125396729\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "train_missing=train_missing.drop(messy_columns,axis=1)\n",
    "test_missing=test_missing.drop(messy_columns,axis=1)\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2860493659973145\n"
     ]
    }
   ],
   "source": [
    "#Remove columns which have too many categories and is string type\n",
    "t1=time.time()\n",
    "messy_columns = []\n",
    "for col in train.columns:\n",
    "    if(train[col].dtype=='O' and len(train[col].unique())>=10):\n",
    "        messy_columns.append(col)\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5496490001678467\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "train=train.drop(messy_columns,axis=1)\n",
    "test=test.drop(messy_columns,axis=1)\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226140, 72)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226140, 41)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226140, 41)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imputed.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3836915493011475\n"
     ]
    }
   ],
   "source": [
    "#Remove the primary key column for data fitting\n",
    "t1=time.time()\n",
    "train = train.drop('innovation_challenge_key',axis=1)\n",
    "test_ids=test['innovation_challenge_key']\n",
    "test = test.drop('innovation_challenge_key',axis=1)\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_imputed.columns:\n",
    "    train[col]=train_imputed[col]\n",
    "    test[col]=test_imputed[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226140,)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[col].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226140, 112)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1888195, 112)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03818345069885254\n"
     ]
    }
   ],
   "source": [
    "#Number of unique values in each columns\n",
    "t1=time.time()\n",
    "catcols=[]\n",
    "scalcols=[]\n",
    "for col in train.columns:\n",
    "    if (train[col].dtype !='object'):\n",
    "        if(len(train[col].unique())<=10):\n",
    "            catcols.append(col)\n",
    "        else:\n",
    "            scalcols.append(col)\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.292438268661499\n"
     ]
    }
   ],
   "source": [
    "#handle catcols\n",
    "t1=time.time()\n",
    "for col in catcols:\n",
    "    train[col]=train[col].astype('category')\n",
    "    test[col]=test[col].astype('category')\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_transaction_type</th>\n",
       "      <th>contract_line_reaction_time_code</th>\n",
       "      <th>sales_hierarchy_level</th>\n",
       "      <th>service_sales_node_base_sales_hierarchy_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>226140</td>\n",
       "      <td>226140</td>\n",
       "      <td>226140</td>\n",
       "      <td>226140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>10002</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>202522</td>\n",
       "      <td>225296</td>\n",
       "      <td>199960</td>\n",
       "      <td>224170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_transaction_type  contract_line_reaction_time_code  \\\n",
       "count                     226140                            226140   \n",
       "unique                         3                                 3   \n",
       "top                        10002                                -1   \n",
       "freq                      202522                            225296   \n",
       "\n",
       "        sales_hierarchy_level  service_sales_node_base_sales_hierarchy_level  \n",
       "count                  226140                                         226140  \n",
       "unique                      6                                              6  \n",
       "top                         6                                              6  \n",
       "freq                   199960                                         224170  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[catcols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cols=[]\n",
    "for col in train.columns:\n",
    "    if(int(len(train[col].unique()))>2 and int(len(train[col].unique()))<4):\n",
    "        embed_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[embed_cols]\n",
    "test_X = test[embed_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in embed_cols:\n",
    "    if len(train_X[col].unique())!= len(test_X[col].unique()):\n",
    "        embed_cols.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cols.extend(['contract_line_net_usd_amount','product_net_price'])\n",
    "train_X = train[embed_cols]\n",
    "test_X = test[embed_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_transaction_type\n",
      "3\n",
      "3\n",
      "contract_line_route_to_market_code\n",
      "3\n",
      "3\n",
      "software_opportunity_type\n",
      "3\n",
      "3\n",
      "service_sales_node_base_country_type\n",
      "3\n",
      "3\n",
      "monetization_type\n",
      "3\n",
      "3\n",
      "product_setup_classification\n",
      "3\n",
      "3\n",
      "discount_category\n",
      "3\n",
      "3\n",
      "service_product_base_business_unit\n",
      "3\n",
      "3\n",
      "global_customer_market_segment_name\n",
      "3\n",
      "3\n",
      "gu_customer_market_segment_name\n",
      "3\n",
      "3\n",
      "country_type\n",
      "3\n",
      "3\n",
      "service_product_base_service_brand_code\n",
      "3\n",
      "3\n",
      "contract_line_net_usd_amount\n",
      "3699\n",
      "6950\n",
      "product_net_price\n",
      "3985\n",
      "9581\n"
     ]
    }
   ],
   "source": [
    "for col in embed_cols:\n",
    "    print(col)\n",
    "    print(len(train[col].unique()))\n",
    "    print(len(test[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_network():\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    model_cat1 = Sequential()\n",
    "    model_cat1.add(Embedding(3, 3, input_length=1))\n",
    "    model_cat1.add(Reshape(target_shape=(3,)))\n",
    "    models.append(model_cat1)\n",
    "    \n",
    "    model_cat2 = Sequential()\n",
    "    model_cat2.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat2.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat2)\n",
    "    \n",
    "    model_cat3 = Sequential()\n",
    "    model_cat3.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat3.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat3)\n",
    "    \n",
    "    model_cat4 = Sequential()\n",
    "    model_cat4.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat4.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat4)\n",
    "    \n",
    "    \n",
    "    model_cat5 = Sequential()\n",
    "    model_cat5.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat5.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat5)\n",
    "    \n",
    "    \n",
    "    model_cat6 = Sequential()\n",
    "    model_cat6.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat6.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat6)\n",
    "    \n",
    "    \n",
    "    model_cat7 = Sequential()\n",
    "    model_cat7.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat7.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat7)\n",
    "    \n",
    "    \n",
    "    model_cat8 = Sequential()\n",
    "    model_cat8.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat8.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat8)\n",
    "    \n",
    "    \n",
    "    model_cat9 = Sequential()\n",
    "    model_cat9.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat9.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat9)\n",
    "    \n",
    "    \n",
    "    model_cat10 = Sequential()\n",
    "    model_cat10.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat10.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat10)\n",
    "    \n",
    "    \n",
    "    model_cat11 = Sequential()\n",
    "    model_cat11.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat11.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat11)\n",
    "    \n",
    "    \n",
    "    model_cat12 = Sequential()\n",
    "    model_cat12.add(Embedding(3, 2, input_length=1))\n",
    "    model_cat12.add(Reshape(target_shape=(2,)))\n",
    "    models.append(model_cat12)\n",
    "    \n",
    "    \n",
    "    #model_rest = Sequential()\n",
    "    #model_rest.add(Dense(16, input_dim=2))\n",
    "    #models.append(model_rest)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Merge(models, mode='concat'))\n",
    "    model.add(Dense(80))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.15))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.15))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=SGD(lr=0.002, momentum=0.0, decay=0.0, nesterov=True), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226140, 14)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1888195, 14)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cols.remove('contract_line_net_usd_amount')\n",
    "embed_cols.remove('product_net_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(X_train, X_val, X_test):\n",
    "\n",
    "    input_list_train = []\n",
    "    input_list_val = []\n",
    "    input_list_test = []\n",
    "    \n",
    "    #the cols to be embedded: rescaling to range [0, # values)\n",
    "    for c in embed_cols:\n",
    "        raw_vals = np.unique(X_train[c])\n",
    "        val_map = {}\n",
    "        for i in range(len(raw_vals)):\n",
    "            val_map[raw_vals[i]] = i       \n",
    "        input_list_train.append(X_train[c].map(val_map).values)\n",
    "        input_list_val.append(X_val[c].map(val_map).fillna(0).values)\n",
    "        input_list_test.append(X_test[c].map(val_map).fillna(0).values)\n",
    "     \n",
    "    #the rest of the columns\n",
    "    #other_cols = [c for c in X_train.columns if (not c in embed_cols)]\n",
    "    #input_list_train.append(X_train[other_cols].values)\n",
    "    #input_list_val.append(X_val[other_cols].values)\n",
    "    #input_list_test.append(X_test[other_cols].values)\n",
    "    \n",
    "    return input_list_train, input_list_val, input_list_test    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ginic(actual, pred):\n",
    "    n = len(actual)\n",
    "    a_s = actual[np.argsort(pred)]\n",
    "    a_c = a_s.cumsum()\n",
    "    giniSum = a_c.sum() / a_c[-1] - (n + 1) / 2.0\n",
    "    return giniSum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_normalizedc(a, p):\n",
    "    return ginic(a, p) / ginic(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=8\n",
    "runs_per_fold = 3\n",
    "n_epochs = 15\n",
    "\n",
    "cv_ginis = []\n",
    "full_val_preds = np.zeros(np.shape(train_X)[0])\n",
    "y_preds = np.zeros((np.shape(test_X)[0],K))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = K, \n",
    "                            random_state = 231, \n",
    "                            shuffle = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/pandas/core/series.py:696: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:79: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\n",
      "Fold 0 prediction cv gini: nan\n",
      "\n",
      "Epoch 1/1\n",
      "\n",
      "Fold 1 prediction cv gini: nan\n",
      "\n",
      "Epoch 1/1\n",
      "\n",
      "Fold 2 prediction cv gini: nan\n",
      "\n",
      "Epoch 1/1\n",
      "\n",
      "Fold 3 prediction cv gini: nan\n",
      "\n",
      "Epoch 1/1\n",
      "\n",
      "Fold 4 prediction cv gini: nan\n",
      "\n",
      "Epoch 1/1\n",
      "\n",
      "Fold 5 prediction cv gini: nan\n",
      "\n",
      "Epoch 1/1\n",
      "\n",
      "Fold 6 prediction cv gini: nan\n",
      "\n",
      "Epoch 1/1\n",
      "\n",
      "Fold 7 prediction cv gini: nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (f_ind, outf_ind) in enumerate(kfold.split(train_X, y_train)):\n",
    "\n",
    "    X_train_f, X_val_f = train_X.loc[f_ind].copy(), train_X.loc[outf_ind].copy()\n",
    "    y_train_f, y_val_f = y_train[f_ind], y_train[outf_ind]\n",
    "    \n",
    "    X_test_f = test_X.copy()\n",
    "    \n",
    "    #upsampling adapted from kernel: \n",
    "    #https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "    pos = (pd.Series(y_train_f == 1))\n",
    "    \n",
    "    # Add positive examples\n",
    "    X_train_f = pd.concat([X_train_f, X_train_f.loc[pos]], axis=0)\n",
    "    y_train_f = pd.concat([y_train_f, y_train_f.loc[pos]], axis=0)\n",
    "    \n",
    "    # Shuffle data\n",
    "    idx = np.arange(len(X_train_f))\n",
    "    np.random.shuffle(idx)\n",
    "    X_train_f = X_train_f.iloc[idx]\n",
    "    y_train_f = y_train_f.iloc[idx]\n",
    "    \n",
    "    #preprocessing\n",
    "    proc_X_train_f, proc_X_val_f, proc_X_test_f = preproc(X_train_f, X_val_f, X_test_f)\n",
    "    \n",
    "    #track oof prediction for cv scores\n",
    "    val_preds = 0\n",
    "    runs_per_fold=1\n",
    "    for j in range(runs_per_fold):\n",
    "    \n",
    "        NN = build_embedding_network()\n",
    "        #print(len(proc_X_train_f))\n",
    "        NN.fit(proc_X_train_f, y_train_f.values, epochs=1,  verbose=3)\n",
    "               #callbacks=[keras.callbacks.TensorBoard(log_dir=\"logs/final/{}\".format(time()), histogram_freq=1, write_graph=True, write_images=True)])\n",
    "   \n",
    "        val_preds += NN.predict(proc_X_val_f)[:,0] / runs_per_fold\n",
    "        y_preds[:,i] += NN.predict(proc_X_test_f)[:,0] / runs_per_fold\n",
    "        \n",
    "    full_val_preds[outf_ind] += val_preds\n",
    "        \n",
    "    cv_gini = gini_normalizedc(y_val_f.values, val_preds)\n",
    "    cv_ginis.append(cv_gini)\n",
    "    print ('\\nFold %i prediction cv gini: %.5f\\n' %(i,cv_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean out of fold gini: nan\n",
      "Full validation gini: -0.03344\n"
     ]
    }
   ],
   "source": [
    "print('Mean out of fold gini: %.5f' % np.mean(cv_ginis))\n",
    "print('Full validation gini: %.5f' % gini_normalizedc(y_train.values, full_val_preds))\n",
    "X_train_pp = preproc(test_X,train_X,train_X)\n",
    "pred = NN.predict(X_train_pp[0])[:,0]\n",
    "#y_pred_final = np.mean(y_preds, axis=1)\n",
    "\n",
    "submit = pd.DataFrame()\n",
    "submit['INNOVATION_CHALLENGE_KEY'] = test_ids\n",
    "#RENEWAL_PROBABLIITY\n",
    "submit['RENEWAL_PROBABLIITY']=pred\n",
    "submit=submit.sort_values('INNOVATION_CHALLENGE_KEY')\n",
    "submit.to_csv('NN_EntityEmbed_10fold-sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1888195"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
