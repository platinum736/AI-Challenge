{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (6,16,17,26,40,41,49,53,97,98,99,100,104,107,109,112,127,128,129,130,220,221,222) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (6,16,17,26,40,41,49,53,54,55,100,104,107,109,112,127,128,129,130,153,171,220,221,222,225,226,227) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_table('challengeData.tsv')\n",
    "test = pd.read_table('scoring_set.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train['challenge_data.renewed_yorn'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove data set name from columns names to make it uniform\n",
    "columns=[]\n",
    "for col in train.columns:\n",
    "    columns.append(col.replace('challenge_data.',''))\n",
    "train.columns=columns\n",
    "columns=[]\n",
    "for col in test.columns:\n",
    "    columns.append(col.replace('scoring_set.',''))\n",
    "test.columns=columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the 'challenge_data.renewed_yorn' from training and test data and move it to a seperate variable\n",
    "train_y=train['renewed_yorn']\n",
    "train = train.drop('renewed_yorn',axis=1)\n",
    "test_y=test['renewed_yorn']\n",
    "test = test.drop('renewed_yorn',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns which have any null values\n",
    "percent = (test.isnull().sum()/test.isnull().count())\n",
    "test.columns[percent>0]\n",
    "#We would ignore all these 102 columns so we are left with 135 columns\n",
    "len(test.columns[percent>0])\n",
    "#all_clean_columns=train.columns[percent==0]\n",
    "#train_clean=train[all_clean_columns]\n",
    "unclean_columns=test.columns[percent>0]\n",
    "train = train.drop(unclean_columns,axis=1)\n",
    "test = test.drop(unclean_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unclean_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns which have too many categories and is string type\n",
    "messy_columns = []\n",
    "for col in test.columns:\n",
    "    if(test[col].dtype=='object' and len(test[col].unique())>20):\n",
    "        messy_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(messy_columns,axis=1)\n",
    "test=test.drop(messy_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226140, 77)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the primary key column for data fitting\n",
    "train_X = train.drop('innovation_challenge_key',axis=1)\n",
    "test_X = test.drop('innovation_challenge_key',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to one hot encoding to handle categorical values\n",
    "train_objs_num = len(train_X)\n",
    "dataset = pd.concat(objs=[train_X, test_X], axis=0)\n",
    "dataset = pd.get_dummies(dataset)\n",
    "train_X = dataset[:train_objs_num]\n",
    "test_X = dataset[train_objs_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NaN left with 0\n",
    "train_X = train_X.fillna(0)\n",
    "test_X = test_X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data between train and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X,train_y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying ensembeling techniques\n",
    "#Starting with bagging\n",
    "clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "\n",
    "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=10, max_samples=0.8, max_features=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.8,\n",
       "         max_samples=0.8, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bagging1.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5972742234071063"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid,pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying Boosting\n",
    "from sklearn import svm\n",
    "svc= svm.SVC(kernel='rbf',probability=True)\n",
    "num_est = [1, 2, 3, 10]\n",
    "label = ['AdaBoost (n_est=1)', 'AdaBoost (n_est=2)', 'AdaBoost (n_est=3)', 'AdaBoost (n_est=10)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "boosting = AdaBoostClassifier(base_estimator=svc, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=boosting.predict_proba(X_valid)\n",
    "log_loss(y_valid,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bagging1.predict_proba(X_valid)\n",
    "log_loss(y_valid,pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying stacking of 3 classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "clf1 = RandomForestClassifier(max_depth=4,random_state=0)\n",
    "clf2 = xgb.XGBClassifier()\n",
    "lr = LogisticRegression(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train,y_train)\n",
    "clf2.fit(X_train,y_train)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clf1 = clf1.predict_proba(X_valid)\n",
    "pred_clf2 = clf2.predict_proba(X_valid)\n",
    "pred_lr = lr.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[]\n",
    "for i in range(0,len(pred_lr)):\n",
    "    pred.append(np.mean([pred_clf1[i][1],pred_clf2[i][1],pred_lr[i][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.567010870428388"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clf1 = clf1.predict_proba(X_valid)\n",
    "pred_clf2 = clf2.predict_proba(X_valid)\n",
    "pred_lr = lr.predict_proba(X_valid)\n",
    "pred=[]\n",
    "for i in range(0,len(pred_lr)):\n",
    "    pred.append(np.mean([pred_clf1[i][1],pred_clf2[i][1],pred_lr[i][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clf1 = clf1.predict_proba(test_X)\n",
    "pred_clf2 = clf2.predict_proba(test_X)\n",
    "pred_lr = lr.predict_proba(test_X)\n",
    "weights = [2,3,1]\n",
    "pred=[]\n",
    "for i in range(0,len(pred_lr)):\n",
    "    x=pred_clf1[i][1]*weights[0]+pred_clf2[i][1]*weights[1]+pred_lr[i][1]*weights[2]\n",
    "    pred.append(x/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit the prediction score\n",
    "submit = pd.DataFrame()\n",
    "submit['INNOVATION_CHALLENGE_KEY'] = test['innovation_challenge_key']\n",
    "#RENEWAL_PROBABLIITY\n",
    "submit['RENEWAL_PROBABLIITY']=pred\n",
    "submit=submit.sort_values('INNOVATION_CHALLENGE_KEY')\n",
    "submit.to_csv('ensemble-wmean_lr_xgb_rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5893879389214136"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying out svm on very small data\n",
    "from sklearn import svm\n",
    "import time\n",
    "t1=time.time()\n",
    "svc= svm.SVC(kernel='rbf',probability=True)\n",
    "svc.fit(X_train.iloc[0:10000,], y_train[0:10000])\n",
    "t2=time.time()\n",
    "pred = svc.predict_proba(X_valid)\n",
    "log_loss(y_valid,pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151513, 257)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying boosting with svm\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
