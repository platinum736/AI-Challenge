{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XGB-fulltrain.csv',\n",
       " 'trainingData.tsv',\n",
       " 'EDA.ipynb',\n",
       " 'Untitled.ipynb',\n",
       " 'EDA_trainData.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'Untitled1.ipynb',\n",
       " 'dataDeck.pdf',\n",
       " 'Ensemble models.ipynb',\n",
       " 'challengeData.tsv',\n",
       " 'sampleData.tsv',\n",
       " 'EDA_Challenge.ipynb',\n",
       " 'ibsaMain.dictionary.xlsx',\n",
       " 'submissionFormat03092018.csv',\n",
       " 'ensemble-wmean_lr_xgb_rf.csv',\n",
       " 'XGB-entiretrain.csv',\n",
       " 'nohup.out',\n",
       " 'lost+found',\n",
       " 'scoring_set.tsv',\n",
       " 'Basic models.ipynb',\n",
       " 'ensemble-mean_lr_xgb_rf.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_table('trainingData.tsv')\n",
    "test = pd.read_table('scoring_set.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train['challenge_data.renewed_yorn'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove data set name from columns names to make it uniform\n",
    "columns=[]\n",
    "for col in train.columns:\n",
    "    columns.append(col.replace('challenge_data.',''))\n",
    "train.columns=columns\n",
    "columns=[]\n",
    "for col in test.columns:\n",
    "    columns.append(col.replace('scoring_set.',''))\n",
    "test.columns=columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the 'challenge_data.renewed_yorn' from training and test data and move it to a seperate variable\n",
    "train_y=train['renewed_yorn']\n",
    "train = train.drop('renewed_yorn',axis=1)\n",
    "test_y=test['renewed_yorn']\n",
    "test = test.drop('renewed_yorn',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns which have any null values\n",
    "percent = (test.isnull().sum()/test.isnull().count())\n",
    "test.columns[percent>0]\n",
    "#We would ignore all these 102 columns so we are left with 135 columns\n",
    "len(test.columns[percent>0])\n",
    "#all_clean_columns=train.columns[percent==0]\n",
    "#train_clean=train[all_clean_columns]\n",
    "unclean_columns=test.columns[percent>0]\n",
    "train = train.drop(unclean_columns,axis=1)\n",
    "test = test.drop(unclean_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unclean_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns which have too many categories and is string type\n",
    "messy_columns = []\n",
    "for col in test.columns:\n",
    "    if(test[col].dtype=='object' and len(test[col].unique())>20):\n",
    "        messy_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(messy_columns,axis=1)\n",
    "test=test.drop(messy_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226140, 77)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the primary key column for data fitting\n",
    "train_X = train.drop('innovation_challenge_key',axis=1)\n",
    "test_X = test.drop('innovation_challenge_key',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to one hot encoding to handle categorical values\n",
    "train_objs_num = len(train_X)\n",
    "dataset = pd.concat(objs=[train_X, test_X], axis=0)\n",
    "dataset = pd.get_dummies(dataset)\n",
    "train_X = dataset[:train_objs_num]\n",
    "test_X = dataset[train_objs_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NaN left with 0\n",
    "train_X = train_X.fillna(0)\n",
    "test_X = test_X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data between train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X,train_y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "t1 = time.time()\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15,10,5), random_state=1)\n",
    "clf.fit(X_train, y_train) \n",
    "t2 =time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.932247638702393"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3142581658067005"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_valid,pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time for xgboost\n",
    "import xgboost as xgb\n",
    "t1 = time.time()\n",
    "model1 = xgb.XGBClassifier()\n",
    "#model2 = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n",
    "xgb1 = model1.fit(X_train, y_train)\n",
    "#xgb2 = model2.fit(X_train.iloc[0:10,], y_train[0:10])\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.73963451385498"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=xgb1.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.549033039678095"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid,pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit the prediction score\n",
    "submit = pd.DataFrame()\n",
    "submit['INNOVATION_CHALLENGE_KEY'] = test['innovation_challenge_key']\n",
    "#RENEWAL_PROBABLIITY\n",
    "submit['RENEWAL_PROBABLIITY']=xgb1.predict_proba(test_X)[:,1]\n",
    "submit=submit.sort_values('INNOVATION_CHALLENGE_KEY')\n",
    "submit.to_csv('XGB-default.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74627"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do a little Gridsearch, Hyperparameter Tunning\n",
    "model3 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "t1 = time.time()\n",
    "xgb3 = model3.fit(X_train, y_train)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564.9680795669556"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.549033039678095"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=xgb1.predict_proba(X_valid)\n",
    "log_loss(y_valid,pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_test = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "t1 = time.time()\n",
    "gsearch = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test, scoring='neg_log_loss',n_jobs=4,iid=False, cv=5)\n",
    "train_model4 = gsearch.fit(X_train, y_train)\n",
    "pred4 = train_model4.predict(X_valid)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
